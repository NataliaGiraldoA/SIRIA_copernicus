{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T20:48:35.531037Z",
     "start_time": "2025-08-02T20:48:35.461308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter"
   ],
   "id": "59e1c21b51309651",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T21:04:21.342330Z",
     "start_time": "2025-08-02T20:48:35.547542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_size = (384, 384)\n",
    "batch_size = 16\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    'C:/Users/Natalia/Desktop/PADIA/SIRIA_copernicus/dataset_soil/training',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    'C:/Users/Natalia/Desktop/PADIA/SIRIA_copernicus/dataset_soil/validation',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    'C:/Users/Natalia/Desktop/PADIA/SIRIA_copernicus/dataset_soil/testing',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Calcular class weights y class distribution\n",
    "def get_class_distribution(dataset):\n",
    "    class_counts = {}\n",
    "    total_samples = 0\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        for label in labels.numpy():\n",
    "            class_name = dataset.class_names[label]\n",
    "            class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "            total_samples += 1\n",
    "\n",
    "    print(\"Distribución de clases:\")\n",
    "    for class_name, count in class_counts.items():\n",
    "        percentage = (count / total_samples) * 100\n",
    "        print(f\"  {class_name}: {count} samples ({percentage:.1f}%)\")\n",
    "\n",
    "    return class_counts, total_samples\n",
    "\n",
    "class_counts, total_samples = get_class_distribution(train_ds)\n",
    "\n",
    "def calculate_moderate_class_weights(class_counts, class_names): #Calcular el class weights moderado para balancear\n",
    "\n",
    "    y_integers = []\n",
    "    for images, labels in train_ds:\n",
    "        y_integers.extend(labels.numpy())\n",
    "\n",
    "\n",
    "    full_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(y_integers),\n",
    "        y=y_integers\n",
    "    )\n",
    "\n",
    "    moderate_weights = np.sqrt(full_weights)\n",
    "\n",
    "    min_weight = np.min(moderate_weights) #Normalizar\n",
    "    moderate_weights = moderate_weights / min_weight\n",
    "\n",
    "    class_weight_dict = dict(zip(np.unique(y_integers), moderate_weights))\n",
    "\n",
    "    print(\"\\nClass weights moderados calculados:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"  {class_name}: {class_weight_dict[i]:.3f}\")\n",
    "\n",
    "    return class_weight_dict\n",
    "\n",
    "class_weights = calculate_moderate_class_weights(class_counts, train_ds.class_names)\n",
    "\n",
    "@register_keras_serializable()\n",
    "class RandomSaturation(layers.Layer):\n",
    "    def __init__(self, factor_min=0.8, factor_max=1.2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.factor_min = factor_min\n",
    "        self.factor_max = factor_max\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            factor = tf.random.uniform([], self.factor_min, self.factor_max)\n",
    "            return tf.image.adjust_saturation(inputs, factor)\n",
    "        return inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'factor_min': self.factor_min,\n",
    "            'factor_max': self.factor_max\n",
    "        })\n",
    "        return config\n",
    "\n",
    "@register_keras_serializable()\n",
    "class RandomHue(layers.Layer):\n",
    "    def __init__(self, delta_min=-0.05, delta_max=0.05, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.delta_min = delta_min\n",
    "        self.delta_max = delta_max\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            delta = tf.random.uniform([], self.delta_min, self.delta_max)\n",
    "            return tf.image.adjust_hue(inputs, delta)\n",
    "        return inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'delta_min': self.delta_min,\n",
    "            'delta_max': self.delta_max\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.3),  # Aumentado de 0.2 a 0.3\n",
    "    layers.RandomZoom(0.2),      # Aumentado de 0.15 a 0.2\n",
    "    layers.RandomContrast(0.2),  # Aumentado de 0.15 a 0.2\n",
    "    layers.RandomBrightness(0.15), # Aumentado de 0.1 a 0.15\n",
    "    layers.RandomTranslation(0.15, 0.15), # Aumentado de 0.1 a 0.15\n",
    "    RandomSaturation(0.7, 1.3),  # Más agresivo: de (0.8,1.2) a (0.7,1.3)\n",
    "    RandomHue(-0.08, 0.08),      # Más agresivo: de (-0.05,0.05) a (-0.08,0.08)\n",
    "    # NUEVO: Añadir ruido gaussiano ocasional\n",
    "    layers.GaussianNoise(0.01),\n",
    "])\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.keras.applications.efficientnet.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "train_ds = train_ds.map(preprocess)\n",
    "val_ds = val_ds.map(preprocess)\n",
    "test_ds = test_ds.map(preprocess)\n",
    "\n",
    "\n",
    "from keras.src.applications.efficientnet import EfficientNetB0\n",
    "base_model = EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(384, 384, 3)\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Resizing(384, 384),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005, weight_decay=0.0001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1,\n",
    "    min_delta=0.001\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.3,\n",
    "    patience=5,\n",
    "    min_lr=1e-9,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\ntraining con class weights\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "def calculate_detailed_metrics(model, dataset, dataset_name, class_names):\n",
    "    print(f\"\\n{dataset_name}\")\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_prob = []\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        predictions = model.predict(images, verbose=0)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted_classes)\n",
    "        y_prob.extend(predictions)\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_prob = np.array(y_prob)\n",
    "\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f} ({accuracy:.2%})\")\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    report = classification_report(y_true, y_pred,\n",
    "                                 target_names=class_names,\n",
    "                                 digits=4)\n",
    "    print(report)\n",
    "\n",
    "    print(f\"\\nConfianza promedi:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_mask = y_true == i\n",
    "        if np.sum(class_mask) > 0:\n",
    "            avg_confidence = np.mean(np.max(y_prob[class_mask], axis=1))\n",
    "            print(f\"  {class_name}: {avg_confidence:.4f}\")\n",
    "\n",
    "print(\"despues de entrenamiento balanceado\")\n",
    "val_loss, val_acc = model.evaluate(val_ds)\n",
    "print(f\"Precisión en validación: {val_acc:.2%}\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"Precisión en test: {test_acc:.2%}\")\n",
    "\n",
    "calculate_detailed_metrics(model, val_ds, \"Validación\", class_names)\n",
    "calculate_detailed_metrics(model, test_ds, \"Test\", class_names)\n"
   ],
   "id": "29ac4e96c84ef972",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1131 files belonging to 4 classes.\n",
      "Found 169 files belonging to 4 classes.\n",
      "Found 169 files belonging to 4 classes.\n",
      "Distribución de clases:\n",
      "  Black Soil: 228 samples (20.2%)\n",
      "  Alluvial soil: 495 samples (43.8%)\n",
      "  Red soil: 239 samples (21.1%)\n",
      "  Clay soil: 169 samples (14.9%)\n",
      "\n",
      "Class weights moderados calculados:\n",
      "  Alluvial soil: 1.000\n",
      "  Black Soil: 1.473\n",
      "  Clay soil: 1.711\n",
      "  Red soil: 1.439\n",
      "\n",
      "training con class weights\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\Natalia\\Desktop\\PADIA\\animales\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m51s\u001B[0m 649ms/step - accuracy: 0.3323 - loss: 8.7475 - val_accuracy: 0.5858 - val_loss: 7.4599 - learning_rate: 5.0000e-04\n",
      "Epoch 2/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 613ms/step - accuracy: 0.4965 - loss: 7.8127 - val_accuracy: 0.6982 - val_loss: 6.8473 - learning_rate: 5.0000e-04\n",
      "Epoch 3/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 605ms/step - accuracy: 0.6067 - loss: 7.0847 - val_accuracy: 0.8166 - val_loss: 6.3024 - learning_rate: 5.0000e-04\n",
      "Epoch 4/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 608ms/step - accuracy: 0.6242 - loss: 6.6971 - val_accuracy: 0.8580 - val_loss: 5.8481 - learning_rate: 5.0000e-04\n",
      "Epoch 5/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 608ms/step - accuracy: 0.7010 - loss: 6.1543 - val_accuracy: 0.8757 - val_loss: 5.3961 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 611ms/step - accuracy: 0.7338 - loss: 5.7699 - val_accuracy: 0.8994 - val_loss: 5.0079 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 626ms/step - accuracy: 0.7524 - loss: 5.3320 - val_accuracy: 0.8876 - val_loss: 4.6482 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 616ms/step - accuracy: 0.7678 - loss: 5.0311 - val_accuracy: 0.9053 - val_loss: 4.3261 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 616ms/step - accuracy: 0.8035 - loss: 4.6804 - val_accuracy: 0.8935 - val_loss: 4.0795 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 613ms/step - accuracy: 0.7856 - loss: 4.4488 - val_accuracy: 0.8817 - val_loss: 3.8567 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 617ms/step - accuracy: 0.7900 - loss: 4.1781 - val_accuracy: 0.9112 - val_loss: 3.5938 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 617ms/step - accuracy: 0.8121 - loss: 3.8573 - val_accuracy: 0.9112 - val_loss: 3.3443 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 690ms/step - accuracy: 0.8313 - loss: 3.6576 - val_accuracy: 0.8817 - val_loss: 3.1963 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 692ms/step - accuracy: 0.8241 - loss: 3.4681 - val_accuracy: 0.9053 - val_loss: 2.9885 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 633ms/step - accuracy: 0.8162 - loss: 3.3291 - val_accuracy: 0.9053 - val_loss: 2.8351 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 643ms/step - accuracy: 0.8228 - loss: 3.0991 - val_accuracy: 0.9172 - val_loss: 2.6653 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 648ms/step - accuracy: 0.8136 - loss: 2.9735 - val_accuracy: 0.9231 - val_loss: 2.5201 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 652ms/step - accuracy: 0.8140 - loss: 2.8471 - val_accuracy: 0.9290 - val_loss: 2.3759 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m55s\u001B[0m 778ms/step - accuracy: 0.8262 - loss: 2.6966 - val_accuracy: 0.9408 - val_loss: 2.2281 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001B[1m71/71\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 685ms/step - accuracy: 0.8356 - loss: 2.5654 - val_accuracy: 0.9467 - val_loss: 2.0987 - learning_rate: 5.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "despues de entrenamiento balanceado\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 577ms/step - accuracy: 0.8985 - loss: 2.2212\n",
      "Precisión en validación: 94.67%\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 532ms/step - accuracy: 0.8700 - loss: 2.2310\n",
      "Precisión en test: 92.90%\n",
      "\n",
      "Validación\n",
      "Accuracy: 0.9467 (94.67%)\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Alluvial soil     0.9524    0.7692    0.8511        26\n",
      "   Black Soil     0.9667    1.0000    0.9831        58\n",
      "    Clay soil     0.8421    1.0000    0.9143        32\n",
      "     Red soil     1.0000    0.9434    0.9709        53\n",
      "\n",
      "     accuracy                         0.9467       169\n",
      "    macro avg     0.9403    0.9282    0.9298       169\n",
      " weighted avg     0.9513    0.9467    0.9459       169\n",
      "\n",
      "\n",
      "Confianza promedi:\n",
      "  Alluvial soil: 0.8091\n",
      "  Black Soil: 0.9617\n",
      "  Clay soil: 0.8335\n",
      "  Red soil: 0.8907\n",
      "\n",
      "Test\n",
      "Accuracy: 0.9290 (92.90%)\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Alluvial soil     0.8696    0.7407    0.8000        27\n",
      "   Black Soil     0.9643    0.9310    0.9474        58\n",
      "    Clay soil     0.8462    1.0000    0.9167        33\n",
      "     Red soil     0.9804    0.9804    0.9804        51\n",
      "\n",
      "     accuracy                         0.9290       169\n",
      "    macro avg     0.9151    0.9130    0.9111       169\n",
      " weighted avg     0.9309    0.9290    0.9278       169\n",
      "\n",
      "\n",
      "Confianza promedi:\n",
      "  Alluvial soil: 0.7694\n",
      "  Black Soil: 0.9328\n",
      "  Clay soil: 0.8966\n",
      "  Red soil: 0.8754\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T21:08:34.521705Z",
     "start_time": "2025-08-02T21:08:34.506687Z"
    }
   },
   "cell_type": "code",
   "source": "class_names = class_names",
   "id": "4c249855a0a781de",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m class_names \u001B[38;5;241m=\u001B[39m \u001B[43mclass_names\u001B[49m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'class_names' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T21:06:16.586647Z",
     "start_time": "2025-08-02T21:06:16.581646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Class names:\", class_names)\n",
    "print(\"Number of classes:\", len(class_names))"
   ],
   "id": "cfd3df7c94b3fe3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['Alluvial soil', 'Black Soil', 'Clay soil', 'Red soil']\n",
      "Number of classes: 4\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T21:06:18.430644Z",
     "start_time": "2025-08-02T21:06:18.414054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# Crear diccionario con los índices de clase\n",
    "class_names = class_names\n",
    "class_indices = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "# Guardar en JSON\n",
    "with open(\"class_indices.json\", \"w\") as f:\n",
    "    json.dump(class_indices, f)\n",
    "\n",
    "print(\"class_indices.json\")"
   ],
   "id": "e2a960030d46dcf9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_indices.json\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T21:06:20.057543Z",
     "start_time": "2025-08-02T21:06:19.828229Z"
    }
   },
   "cell_type": "code",
   "source": "model.save(\"soil_classifier.keras\")",
   "id": "e0e348f152d57004",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T21:10:46.571518Z",
     "start_time": "2025-08-02T21:10:42.183496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from custom_layers import RandomHue, RandomSaturation\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"soil_classifier.keras\")"
   ],
   "id": "97289fe4b50fccf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Natalia\\Desktop\\PADIA\\animales\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T21:10:50.095464Z",
     "start_time": "2025-08-02T21:10:50.013846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "img_size = (384, 384)\n",
    "batch_size = 16\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    'C:/Users/Natalia/Desktop/PADIA/SIRIA_copernicus/dataset_soil/training',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "print(class_names)"
   ],
   "id": "afead3840b07e475",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1131 files belonging to 4 classes.\n",
      "['Alluvial soil', 'Black Soil', 'Clay soil', 'Red soil']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T21:11:35.823825Z",
     "start_time": "2025-08-02T21:11:35.741485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "img_path = \"C:/Users/Natalia/Desktop/PADIA/SIRIA_copernicus/dataset_soil/testing/Red soil/Red_13.jpg\"  # Cambia esto por la ruta de tu imagen\n",
    "img_size = (384,384)\n",
    "\n",
    "\n",
    "# Cargar imagen y redimensionar\n",
    "img = load_img(img_path, target_size=img_size)\n",
    "\n",
    "# Convertir a array y escalar\n",
    "img_array = img_to_array(img)\n",
    "img_array = preprocess_input(img_array)  # Normalizar igual que en el modelo\n",
    "\n",
    "# Expandir dimensiones para simular un batch de tamaño 1\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "class_names = class_names\n",
    "\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "confidence = 100 * np.max(predictions[0])\n",
    "\n",
    "print(f\"La imagen probablemente pertenece a '{class_names[predicted_class]}' con una confianza de {confidence:.2f}%\")"
   ],
   "id": "c401eeb064918b1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "La imagen probablemente pertenece a 'Red soil' con una confianza de 71.32%\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
